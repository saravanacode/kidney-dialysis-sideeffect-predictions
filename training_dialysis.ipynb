{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5000 patient records with 55 columns.\n",
      "First few records:\n",
      "  PatientID  Age  Gender  Weight   BMI Diabetes Hypertension  \\\n",
      "0      P001   72    Male    97.7  34.2      Yes          Yes   \n",
      "1      P002   70  Female    57.0  19.5       No          Yes   \n",
      "\n",
      "   Kidney_Failure_Cause Pre_Dialysis_Blood_Pressure  \\\n",
      "0  Diabetic Nephropathy                      170/89   \n",
      "1  Diabetic Nephropathy                      127/80   \n",
      "\n",
      "  During_Dialysis_Blood_Pressure  ... Time_To_Recovery_Hours  \\\n",
      "0                         158/82  ...                      0   \n",
      "1                         111/66  ...                      6   \n",
      "\n",
      "   Pre_Dialysis_Symptoms  Interdialytic_Weight_Gain  Diet_Compliance  \\\n",
      "0                   None                        2.2             Good   \n",
      "1                   None                        1.5             Poor   \n",
      "\n",
      "   Fluid_Restriction_Compliance  Recent_Food_Intake       Side_Effect_Type  \\\n",
      "0                          Good       Balanced Meal  Muscle Cramps;Itching   \n",
      "1                          Good    Low Protein Meal   Hypotension;Vomiting   \n",
      "\n",
      "   Side_Effect_Severity  Side_Effect_Timing  Staff_Intervention_Required  \n",
      "0                  Mild      Post-Treatment                          Yes  \n",
      "1                Severe        Middle Hours                           No  \n",
      "\n",
      "[2 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Define number of patients\n",
    "num_patients = 5000\n",
    "\n",
    "# Helper functions for generating realistic data\n",
    "def generate_patient_id(i):\n",
    "    return f\"P{str(i+1).zfill(3)}\"\n",
    "\n",
    "def generate_age():\n",
    "    # Most dialysis patients are older, weighted distribution\n",
    "    return int(np.random.normal(65, 15))\n",
    "\n",
    "def generate_gender():\n",
    "    return random.choice([\"Male\", \"Female\"])\n",
    "\n",
    "def generate_weight():\n",
    "    # In kg, normal distribution\n",
    "    return round(np.random.normal(75, 35), 1)\n",
    "\n",
    "def generate_bmi(weight, height):\n",
    "    # BMI = weight(kg) / height(m)^2\n",
    "    return round(weight / (height ** 2), 1)\n",
    "\n",
    "def generate_bp():\n",
    "    # Generate blood pressure as systolic/diastolic\n",
    "    systolic = int(np.random.normal(140, 20))\n",
    "    diastolic = int(np.random.normal(85, 15))\n",
    "    return f\"{systolic}/{diastolic}\"\n",
    "\n",
    "def generate_kidney_failure_cause():\n",
    "    causes = [\"Diabetic Nephropathy\", \"Hypertensive Nephrosclerosis\",\n",
    "              \"Glomerulonephritis\", \"Polycystic Kidney Disease\",\n",
    "              \"Interstitial Nephritis\", \"Obstructive Nephropathy\"]\n",
    "    weights = [0.35, 0.25, 0.15, 0.10, 0.10, 0.05]\n",
    "    return np.random.choice(causes, p=weights)\n",
    "\n",
    "def generate_lab_value(mean, std, decimal_places=1):\n",
    "    return round(np.random.normal(mean, std), decimal_places)\n",
    "\n",
    "\n",
    "def generate_dialysate_composition():\n",
    "    k_levels = [\"K+:2.0\", \"K+:2.5\", \"K+:3.0\"]\n",
    "    ca_levels = [\"Ca:2.5\", \"Ca:3.0\", \"Ca:3.5\"]\n",
    "    na_levels = [\"Na:138\", \"Na:140\", \"Na:142\"]\n",
    "\n",
    "    k = random.choice(k_levels)\n",
    "    ca = random.choice(ca_levels)\n",
    "    na = random.choice(na_levels)\n",
    "\n",
    "    return f\"{k} {ca} {na}\"\n",
    "\n",
    "def generate_vascular_access():\n",
    "    access_types = [\"AVF\", \"AVG\", \"CVC\", \"Tunneled Catheter\"]\n",
    "    weights = [0.5, 0.2, 0.15, 0.15]\n",
    "    return np.random.choice(access_types, p=weights)\n",
    "\n",
    "def generate_dialyzer_type():\n",
    "    return random.choice([\"High-Flux\", \"Low-Flux\", \"Medium-Flux\"])\n",
    "\n",
    "def generate_severity():\n",
    "    return random.choice([\"Mild\", \"Moderate\", \"Severe\", \"Critical\"])\n",
    "\n",
    "def generate_yes_no(yes_prob=0.5):\n",
    "    return \"Yes\" if random.random() < yes_prob else \"No\"\n",
    "\n",
    "def generate_medications():\n",
    "    meds = [\"Amlodipine\", \"Metoprolol\", \"Lisinopril\", \"Carvedilol\",\n",
    "            \"Losartan\", \"Atenolol\", \"Furosemide\", \"Hydrochlorothiazide\",\n",
    "            \"Nifedipine\", \"Doxazosin\"]\n",
    "\n",
    "    # Choose 0-3 medications\n",
    "    num_meds = random.randint(0, 3)\n",
    "    if num_meds == 0:\n",
    "        return \"None\"\n",
    "\n",
    "    selected_meds = random.sample(meds, num_meds)\n",
    "    return \";\".join(selected_meds)\n",
    "\n",
    "def generate_phosphate_binders():\n",
    "    binders = [\"Sevelamer\", \"Calcium Acetate\", \"Lanthanum Carbonate\",\n",
    "               \"Ferric Citrate\", \"Aluminum Hydroxide\", \"None\"]\n",
    "    weights = [0.3, 0.25, 0.15, 0.1, 0.05, 0.15]\n",
    "    return np.random.choice(binders, p=weights)\n",
    "\n",
    "def generate_comorbidities():\n",
    "    conditions = [\"CAD\", \"CHF\", \"Diabetes\", \"Hypertension\", \"PVD\",\n",
    "                  \"Stroke\", \"COPD\", \"Depression\", \"Gout\", \"Anemia\"]\n",
    "\n",
    "    # Choose 0-4 comorbidities\n",
    "    num_conditions = random.randint(0, 4)\n",
    "    if num_conditions == 0:\n",
    "        return \"None\"\n",
    "\n",
    "    selected_conditions = random.sample(conditions, num_conditions)\n",
    "    return \";\".join(selected_conditions)\n",
    "\n",
    "def generate_side_effects():\n",
    "    effects = [\"Muscle Cramps\", \"Hypotension\", \"Nausea\", \"Vomiting\",\n",
    "               \"Headache\", \"Dizziness\", \"Chest Pain\", \"Itching\",\n",
    "               \"Fever\", \"Chills\", \"None\"]\n",
    "\n",
    "    # Choose 0-3 side effects\n",
    "    num_effects = random.randint(0, 3)\n",
    "    if num_effects == 0:\n",
    "        return \"None\"\n",
    "\n",
    "    selected_effects = random.sample(effects[:10], num_effects)\n",
    "    return \";\".join(selected_effects)\n",
    "\n",
    "def generate_symptoms():\n",
    "    symptoms = [\"Fatigue\", \"Nausea\", \"Shortness of Breath\", \"Edema\",\n",
    "                \"Loss of Appetite\", \"Itching\", \"Muscle Cramps\", \"Insomnia\",\n",
    "                \"None\"]\n",
    "\n",
    "    # Choose 0-3 symptoms\n",
    "    num_symptoms = random.randint(0, 3)\n",
    "    if num_symptoms == 0:\n",
    "        return \"None\"\n",
    "\n",
    "    selected_symptoms = random.sample(symptoms[:8], num_symptoms)\n",
    "    return \";\".join(selected_symptoms)\n",
    "\n",
    "def generate_compliance():\n",
    "    return random.choice([\"Poor\", \"Moderate\", \"Good\", \"Excellent\"])\n",
    "\n",
    "def generate_food_intake():\n",
    "    foods = [\"High Sodium Meal\", \"High Potassium Meal\", \"High Phosphorus Meal\",\n",
    "             \"Low Protein Meal\", \"Balanced Meal\", \"Skipped Meal\", \"Liquid Only\"]\n",
    "    return random.choice(foods)\n",
    "\n",
    "def generate_timing():\n",
    "    return random.choice([\"First Hour\", \"Middle Hours\", \"Last Hour\", \"Post-Treatment\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create empty DataFrame\n",
    "data = []\n",
    "\n",
    "for i in range(num_patients):\n",
    "    # Generate basic patient info\n",
    "    patient_id = generate_patient_id(i)\n",
    "    age = generate_age()\n",
    "    gender = generate_gender()\n",
    "    height = round(np.random.normal(1.7, 0.1), 2)  # in meters\n",
    "    weight = generate_weight()\n",
    "    bmi = generate_bmi(weight, height)\n",
    "\n",
    "    # Generate medical conditions\n",
    "    diabetes = generate_yes_no(0.4)\n",
    "    hypertension = generate_yes_no(0.7)\n",
    "    kidney_failure_cause = generate_kidney_failure_cause()\n",
    "\n",
    "    # Generate blood pressure readings\n",
    "    pre_dialysis_bp = generate_bp()\n",
    "    # During dialysis BP typically lower\n",
    "    systolic_pre, diastolic_pre = map(int, pre_dialysis_bp.split('/'))\n",
    "    systolic_during = max(90, systolic_pre - random.randint(5, 20))\n",
    "    diastolic_during = max(60, diastolic_pre - random.randint(5, 15))\n",
    "    during_dialysis_bp = f\"{systolic_during}/{diastolic_during}\"\n",
    "\n",
    "    # Post dialysis BP typically even lower or stabilized\n",
    "    systolic_post = max(90, systolic_during - random.randint(-5, 15))\n",
    "    diastolic_post = max(60, diastolic_during - random.randint(-5, 10))\n",
    "    post_dialysis_bp = f\"{systolic_post}/{diastolic_post}\"\n",
    "\n",
    "    # Generate other vital signs and lab values\n",
    "    heart_rate = int(np.random.normal(80, 15))\n",
    "    creatinine = generate_lab_value(8.0, 2.0, 1)\n",
    "    urea = generate_lab_value(120, 30, 0)\n",
    "    potassium = generate_lab_value(5.0, 0.8, 1)\n",
    "    hemoglobin = generate_lab_value(10.0, 1.5, 1)\n",
    "    hematocrit = generate_lab_value(30.0, 5.0, 1)\n",
    "    albumin = generate_lab_value(3.5, 0.5, 1)\n",
    "    calcium = generate_lab_value(8.5, 0.5, 1)\n",
    "    phosphorus = generate_lab_value(5.5, 1.0, 1)\n",
    "\n",
    "    # Generate dialysis parameters\n",
    "    dialysis_duration = random.choice([3, 3.5, 4, 4.5, 5])\n",
    "    dialysis_frequency = random.choice([2, 3, 4])\n",
    "    dialysate_composition = generate_dialysate_composition()\n",
    "    vascular_access = generate_vascular_access()\n",
    "    dialyzer_type = generate_dialyzer_type()\n",
    "    ktv = generate_lab_value(1.4, 0.2, 1)\n",
    "    urr = generate_lab_value(70, 5, 0)\n",
    "    urine_output = int(np.random.normal(200, 150))\n",
    "    dry_weight = round(weight - random.uniform(1, 5), 1)\n",
    "    fluid_removal_rate = int(np.random.normal(800, 200))\n",
    "\n",
    "    # Generate disease and treatment info\n",
    "    disease_severity = generate_severity()\n",
    "    pre_dialysis_weight = round(dry_weight + random.uniform(1, 5), 1)\n",
    "    post_dialysis_weight = round(dry_weight + random.uniform(-0.5, 1), 1)\n",
    "    recent_medication_changes = generate_yes_no(0.3)\n",
    "    antihypertensive_meds = generate_medications()\n",
    "    epo_dose = random.choice([0, 2000, 3000, 4000, 6000])\n",
    "    iron_supplements = random.choice([\"None\", \"Ferrous Sulfate\", \"Iron Sucrose\", \"Ferric Gluconate\"])\n",
    "    phosphate_binders = generate_phosphate_binders()\n",
    "    blood_transfusion = generate_yes_no(0.1)\n",
    "    intradialytic_medication = random.choice([\"None\", \"Saline\", \"Albumin\", \"Antibiotics\", \"Antiemetics\"])\n",
    "    recent_infection = generate_yes_no(0.15)\n",
    "    comorbidities = generate_comorbidities()\n",
    "    serum_sodium = int(np.random.normal(138, 3))\n",
    "\n",
    "    # Generate side effect info\n",
    "    previous_side_effects = generate_side_effects()\n",
    "    if previous_side_effects == \"None\":\n",
    "        days_since_last_side_effect = 0\n",
    "        time_to_recovery = 0\n",
    "    else:\n",
    "        days_since_last_side_effect = random.randint(1, 30)\n",
    "        time_to_recovery = random.randint(1, 12)\n",
    "\n",
    "    pre_dialysis_symptoms = generate_symptoms()\n",
    "    interdialytic_weight_gain = round(random.uniform(0.5, 5.0), 1)\n",
    "    diet_compliance = generate_compliance()\n",
    "    fluid_compliance = generate_compliance()\n",
    "    recent_food_intake = generate_food_intake()\n",
    "\n",
    "    # Generate current side effect details\n",
    "    current_side_effect_type = generate_side_effects()\n",
    "    if current_side_effect_type == \"None\":\n",
    "        side_effect_severity = \"None\"\n",
    "        side_effect_timing = \"None\"\n",
    "        staff_intervention = \"No\"\n",
    "    else:\n",
    "        side_effect_severity = generate_severity()\n",
    "        side_effect_timing = generate_timing()\n",
    "        staff_intervention = generate_yes_no(0.6)\n",
    "\n",
    "    # Create a patient record\n",
    "    patient = {\n",
    "        \"PatientID\": patient_id,\n",
    "        \"Age\": age,\n",
    "        \"Gender\": gender,\n",
    "        \"Weight\": weight,\n",
    "        \"BMI\": bmi,\n",
    "        \"Diabetes\": diabetes,\n",
    "        \"Hypertension\": hypertension,\n",
    "        \"Kidney_Failure_Cause\": kidney_failure_cause,\n",
    "        \"Pre_Dialysis_Blood_Pressure\": pre_dialysis_bp,\n",
    "        \"During_Dialysis_Blood_Pressure\": during_dialysis_bp,\n",
    "        \"Post_Dialysis_Blood_Pressure\": post_dialysis_bp,\n",
    "        \"Heart_Rate\": heart_rate,\n",
    "        \"Creatinine\": creatinine,\n",
    "        \"Urea\": urea,\n",
    "        \"Potassium\": potassium,\n",
    "        \"Hemoglobin\": hemoglobin,\n",
    "        \"Hematocrit\": hematocrit,\n",
    "        \"Albumin\": albumin,\n",
    "        \"Calcium\": calcium,\n",
    "        \"Phosphorus\": phosphorus,\n",
    "        \"Dialysis_Duration_Hours\": dialysis_duration,\n",
    "        \"Dialysis_Frequency_Per_Week\": dialysis_frequency,\n",
    "        \"Dialysate_Composition\": dialysate_composition,\n",
    "        \"Vascular_Access_Type\": vascular_access,\n",
    "        \"Dialyzer_Type\": dialyzer_type,\n",
    "        \"KtV\": ktv,\n",
    "        \"URR\": urr,\n",
    "        \"Urine_Output_ml_day\": urine_output,\n",
    "        \"Dry_Weight_kg\": dry_weight,\n",
    "        \"Fluid_Removal_Rate_ml_hour\": fluid_removal_rate,\n",
    "        \"Disease_Severity\": disease_severity,\n",
    "        \"Pre_Dialysis_Weight_kg\": pre_dialysis_weight,\n",
    "        \"Post_Dialysis_Weight_kg\": post_dialysis_weight,\n",
    "        \"Recent_Medication_Changes\": recent_medication_changes,\n",
    "        \"Antihypertensive_Meds\": antihypertensive_meds,\n",
    "        \"EPO_Dose\": epo_dose,\n",
    "        \"Iron_Supplements\": iron_supplements,\n",
    "        \"Phosphate_Binders\": phosphate_binders,\n",
    "        \"Blood_Transfusion_Recent\": blood_transfusion,\n",
    "        \"Intradialytic_Medication\": intradialytic_medication,\n",
    "        \"Recent_Infection\": recent_infection,\n",
    "        \"Comorbidities\": comorbidities,\n",
    "        \"Serum_Sodium\": serum_sodium,\n",
    "        \"Previous_Side_Effects\": previous_side_effects,\n",
    "        \"Days_Since_Last_Side_Effect\": days_since_last_side_effect,\n",
    "        \"Time_To_Recovery_Hours\": time_to_recovery,\n",
    "        \"Pre_Dialysis_Symptoms\": pre_dialysis_symptoms,\n",
    "        \"Interdialytic_Weight_Gain\": interdialytic_weight_gain,\n",
    "        \"Diet_Compliance\": diet_compliance,\n",
    "        \"Fluid_Restriction_Compliance\": fluid_compliance,\n",
    "        \"Recent_Food_Intake\": recent_food_intake,\n",
    "        \"Side_Effect_Type\": current_side_effect_type,\n",
    "        \"Side_Effect_Severity\": side_effect_severity,\n",
    "        \"Side_Effect_Timing\": side_effect_timing,\n",
    "        \"Staff_Intervention_Required\": staff_intervention\n",
    "    }\n",
    "\n",
    "    data.append(patient)\n",
    "\n",
    "# Create DataFrame and save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"dialysis_patient_dataset.csv\", index=False)\n",
    "\n",
    "print(f\"Generated {num_patients} patient records with {len(df.columns)} columns.\")\n",
    "print(\"First few records:\")\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the dialysis patient data...\n",
      "Dataset loaded with 5000 rows and 55 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 1: Load and preprocess the data\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"Loading and preprocessing the dialysis patient data...\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dialysis_patient_dataset.csv\")\n",
    "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess side effects\n",
    "def preprocess_side_effects(side_effect_column):\n",
    "    side_effects_list = []\n",
    "\n",
    "    for effect_str in side_effect_column:\n",
    "        effects = set()\n",
    "        if pd.notna(effect_str) and effect_str != \"None\":\n",
    "            effect_str = str(effect_str)\n",
    "            for effect in effect_str.split(\";\"):\n",
    "                effects.add(effect)\n",
    "        side_effects_list.append(list(effects))\n",
    "\n",
    "    # Convert to binary format\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    side_effects_encoded = mlb.fit_transform(side_effects_list)\n",
    "    side_effect_df = pd.DataFrame(side_effects_encoded, columns=mlb.classes_)\n",
    "\n",
    "    return side_effect_df, mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any missing values\n",
    "df = df.fillna({\n",
    "    \"Side_Effect_Type\": \"None\",\n",
    "    \"Side_Effect_Severity\": \"None\",\n",
    "    \"Side_Effect_Timing\": \"None\",\n",
    "    \"Staff_Intervention_Required\": \"No\"\n",
    "})\n",
    "\n",
    "side_effects_df, side_effect_mlb = preprocess_side_effects(df[\"Side_Effect_Type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoders for the other target variables\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "severity_encoder = LabelEncoder()\n",
    "df[\"Side_Effect_Severity_Encoded\"] = severity_encoder.fit_transform(df[\"Side_Effect_Severity\"])\n",
    "\n",
    "timing_encoder = LabelEncoder()\n",
    "df[\"Side_Effect_Timing_Encoded\"] = timing_encoder.fit_transform(df[\"Side_Effect_Timing\"])\n",
    "\n",
    "intervention_encoder = LabelEncoder()\n",
    "df[\"Staff_Intervention_Encoded\"] = intervention_encoder.fit_transform(df[\"Staff_Intervention_Required\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from targets\n",
    "X = df.drop([\n",
    "    \"PatientID\", \"Side_Effect_Type\", \"Side_Effect_Severity\",\n",
    "    \"Side_Effect_Timing\", \"Staff_Intervention_Required\",\n",
    "    \"Side_Effect_Severity_Encoded\", \"Side_Effect_Timing_Encoded\",\n",
    "    \"Staff_Intervention_Encoded\"\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle any remaining NaN values in features\n",
    "for col in X.select_dtypes(include=[\"int64\", \"float64\"]).columns:\n",
    "    X[col] = X[col].fillna(X[col].mean())\n",
    "\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "# Target variables\n",
    "y_side_effects = side_effects_df\n",
    "y_severity = df[\"Side_Effect_Severity_Encoded\"]\n",
    "y_timing = df[\"Side_Effect_Timing_Encoded\"]\n",
    "y_intervention = df[\"Staff_Intervention_Encoded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 26\n",
      "Categorical features: 24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), categorical_features)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4000 samples\n",
      "Testing set size: 1000 samples\n",
      "Processed feature count: 9616\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, \\\n",
    "y_side_train, y_side_test, \\\n",
    "y_sev_train, y_sev_test, \\\n",
    "y_time_train, y_time_test, \\\n",
    "y_int_train, y_int_test = train_test_split(\n",
    "    X, y_side_effects, y_severity, y_timing, y_intervention,\n",
    "    test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Processed feature count: {X_train_processed.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training machine learning classifiers with specialized algorithms...\n",
      "Side Effect Type model trained (RandomForest)\n",
      "Severity model trained (GradientBoosting)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3198\n",
      "[LightGBM] [Info] Number of data points in the train set: 4000, number of used features: 175\n",
      "[LightGBM] [Info] Start training from score -1.619488\n",
      "[LightGBM] [Info] Start training from score -1.709258\n",
      "[LightGBM] [Info] Start training from score -1.699636\n",
      "[LightGBM] [Info] Start training from score -1.407518\n",
      "[LightGBM] [Info] Start training from score -1.642478\n",
      "Timing model trained (LightGBM)\n",
      "Intervention model trained (LogisticRegression)\n",
      "\n",
      "Evaluating classifier performance...\n",
      "\n",
      "Side Effect Type Classification Report (RandomForest):\n",
      "\n",
      "Chest Pain:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       842\n",
      "           1       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.71      0.84      0.77      1000\n",
      "\n",
      "\n",
      "Chills:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       848\n",
      "           1       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.72      0.85      0.78      1000\n",
      "\n",
      "\n",
      "Dizziness:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       871\n",
      "           1       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.44      0.50      0.47      1000\n",
      "weighted avg       0.76      0.87      0.81      1000\n",
      "\n",
      "\n",
      "Fever:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       870\n",
      "           1       0.00      0.00      0.00       130\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.43      0.50      0.47      1000\n",
      "weighted avg       0.76      0.87      0.81      1000\n",
      "\n",
      "\n",
      "Headache:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       839\n",
      "           1       0.00      0.00      0.00       161\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.70      0.84      0.77      1000\n",
      "\n",
      "\n",
      "Hypotension:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       865\n",
      "           1       0.00      0.00      0.00       135\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.43      0.50      0.46      1000\n",
      "weighted avg       0.75      0.86      0.80      1000\n",
      "\n",
      "\n",
      "Itching:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       836\n",
      "           1       0.00      0.00      0.00       164\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.70      0.84      0.76      1000\n",
      "\n",
      "\n",
      "Muscle Cramps:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       863\n",
      "           1       0.00      0.00      0.00       137\n",
      "\n",
      "    accuracy                           0.86      1000\n",
      "   macro avg       0.43      0.50      0.46      1000\n",
      "weighted avg       0.74      0.86      0.80      1000\n",
      "\n",
      "\n",
      "Nausea:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       837\n",
      "           1       0.00      0.00      0.00       163\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.70      0.84      0.76      1000\n",
      "\n",
      "\n",
      "Vomiting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       848\n",
      "           1       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.42      0.50      0.46      1000\n",
      "weighted avg       0.72      0.85      0.78      1000\n",
      "\n",
      "\n",
      "Severity Classification Report (GradientBoosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.09       183\n",
      "           1       0.22      0.10      0.14       178\n",
      "           2       0.21      0.06      0.09       176\n",
      "           3       0.27      0.80      0.41       260\n",
      "           4       0.27      0.06      0.10       203\n",
      "\n",
      "    accuracy                           0.26      1000\n",
      "   macro avg       0.23      0.21      0.16      1000\n",
      "weighted avg       0.23      0.26      0.18      1000\n",
      "\n",
      "Accuracy: 0.2580\n",
      "\n",
      "Timing Classification Report (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.21      0.20       189\n",
      "           1       0.21      0.14      0.17       175\n",
      "           2       0.13      0.09      0.11       184\n",
      "           3       0.28      0.39      0.32       260\n",
      "           4       0.23      0.22      0.22       192\n",
      "\n",
      "    accuracy                           0.23      1000\n",
      "   macro avg       0.21      0.21      0.21      1000\n",
      "weighted avg       0.21      0.23      0.22      1000\n",
      "\n",
      "Accuracy: 0.2250\n",
      "\n",
      "Intervention Required Classification Report (LogisticRegression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.53      0.54       559\n",
      "           1       0.43      0.44      0.44       441\n",
      "\n",
      "    accuracy                           0.49      1000\n",
      "   macro avg       0.49      0.49      0.49      1000\n",
      "weighted avg       0.50      0.49      0.49      1000\n",
      "\n",
      "Accuracy: 0.4940\n",
      "\n",
      "Saving models and encoders...\n",
      "Models and encoders saved successfully!\n",
      "\n",
      "The models have been updated with specialized algorithms!\n",
      "- Side Effect Type: RandomForest (good for multi-label classification)\n",
      "- Severity: GradientBoosting (handles ordinal data well)\n",
      "- Timing: LightGBM (efficient for multi-class problems)\n",
      "- Intervention Required: LogisticRegression (interpretable for binary tasks)\n",
      "\n",
      "You can now use predict_side_effects() to get predictions with confidence scores.\n"
     ]
    }
   ],
   "source": [
    "# Updated machine learning approach using different algorithms for each prediction task\n",
    "# ------------------------------------------\n",
    "# Step 2: Build and train the classifiers (Updated with different algorithms)\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nTraining machine learning classifiers with specialized algorithms...\")\n",
    "\n",
    "# Import additional models\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# You can install these packages with:\n",
    "# pip install lightgbm xgboost\n",
    "\n",
    "# 1. Side Effect Type Classifier (Multi-label) - Keep RandomForest for this complex task\n",
    "side_effect_model = MultiOutputClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    ")\n",
    "side_effect_model.fit(X_train_processed, y_side_train)\n",
    "print(\"Side Effect Type model trained (RandomForest)\")\n",
    "\n",
    "# 2. Severity Classifier - Use Gradient Boosting for ordinal classification\n",
    "severity_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "severity_model.fit(X_train_processed, y_sev_train)\n",
    "print(\"Severity model trained (GradientBoosting)\")\n",
    "\n",
    "# 3. Timing Classifier - Use LightGBM for multi-class classification\n",
    "timing_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100,\n",
    "    num_leaves=31,\n",
    "    random_state=42\n",
    ")\n",
    "timing_model.fit(X_train_processed, y_time_train)\n",
    "print(\"Timing model trained (LightGBM)\")\n",
    "\n",
    "# 4. Intervention Required Classifier - Use Logistic Regression for binary classification\n",
    "intervention_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "intervention_model.fit(X_train_processed, y_int_train)\n",
    "print(\"Intervention model trained (LogisticRegression)\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 3: Evaluate the classifiers (unchanged, but we'll compare performance)\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nEvaluating classifier performance...\")\n",
    "\n",
    "# 1. Evaluate Side Effect Type predictions (RandomForest)\n",
    "side_effect_pred = side_effect_model.predict(X_test_processed)\n",
    "side_effect_classes = side_effect_mlb.classes_\n",
    "\n",
    "print(\"\\nSide Effect Type Classification Report (RandomForest):\")\n",
    "for i, effect in enumerate(side_effect_classes):\n",
    "    print(f\"\\n{effect}:\")\n",
    "    print(classification_report(y_side_test.iloc[:, i], side_effect_pred[:, i], zero_division=0))\n",
    "\n",
    "# 2. Evaluate Severity predictions (GradientBoosting)\n",
    "severity_pred = severity_model.predict(X_test_processed)\n",
    "print(\"\\nSeverity Classification Report (GradientBoosting):\")\n",
    "print(classification_report(y_sev_test, severity_pred, zero_division=0))\n",
    "print(f\"Accuracy: {accuracy_score(y_sev_test, severity_pred):.4f}\")\n",
    "\n",
    "# 3. Evaluate Timing predictions (LightGBM)\n",
    "timing_pred = timing_model.predict(X_test_processed)\n",
    "print(\"\\nTiming Classification Report (LightGBM):\")\n",
    "print(classification_report(y_time_test, timing_pred, zero_division=0))\n",
    "print(f\"Accuracy: {accuracy_score(y_time_test, timing_pred):.4f}\")\n",
    "\n",
    "# 4. Evaluate Intervention predictions (LogisticRegression)\n",
    "intervention_pred = intervention_model.predict(X_test_processed)\n",
    "print(\"\\nIntervention Required Classification Report (LogisticRegression):\")\n",
    "print(classification_report(y_int_test, intervention_pred, zero_division=0))\n",
    "print(f\"Accuracy: {accuracy_score(y_int_test, intervention_pred):.4f}\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 4: Save the models and preprocessors\n",
    "# ------------------------------------------\n",
    "\n",
    "print(\"\\nSaving models and encoders...\")\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, \"dialysis_preprocessor.pkl\")\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(side_effect_model, \"side_effect_model.pkl\")\n",
    "joblib.dump(severity_model, \"severity_model.pkl\")\n",
    "joblib.dump(timing_model, \"timing_model.pkl\")\n",
    "joblib.dump(intervention_model, \"intervention_model.pkl\")\n",
    "\n",
    "# Save the encoders\n",
    "joblib.dump(side_effect_mlb, \"side_effect_mlb.pkl\")\n",
    "joblib.dump(severity_encoder, \"severity_encoder.pkl\")\n",
    "joblib.dump(timing_encoder, \"timing_encoder.pkl\")\n",
    "joblib.dump(intervention_encoder, \"intervention_encoder.pkl\")\n",
    "\n",
    "print(\"Models and encoders saved successfully!\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Step 5: Updated prediction function to use the new models\n",
    "# ------------------------------------------\n",
    "\n",
    "def predict_side_effects(patient_data):\n",
    "    \"\"\"\n",
    "    Predict side effects for a patient using the specialized algorithms\n",
    "\n",
    "    Args:\n",
    "        patient_data: DataFrame with a single patient's data\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with predictions\n",
    "    \"\"\"\n",
    "    # Load the models and preprocessors\n",
    "    preprocessor = joblib.load(\"dialysis_preprocessor.pkl\")\n",
    "    side_effect_model = joblib.load(\"side_effect_model.pkl\")  # RandomForest\n",
    "    severity_model = joblib.load(\"severity_model.pkl\")        # GradientBoosting\n",
    "    timing_model = joblib.load(\"timing_model.pkl\")            # LightGBM\n",
    "    intervention_model = joblib.load(\"intervention_model.pkl\") # LogisticRegression\n",
    "\n",
    "    # Load the encoders\n",
    "    side_effect_mlb = joblib.load(\"side_effect_mlb.pkl\")\n",
    "    severity_encoder = joblib.load(\"severity_encoder.pkl\")\n",
    "    timing_encoder = joblib.load(\"timing_encoder.pkl\")\n",
    "    intervention_encoder = joblib.load(\"intervention_encoder.pkl\")\n",
    "\n",
    "    # Make sure patient_data is a DataFrame\n",
    "    if not isinstance(patient_data, pd.DataFrame):\n",
    "        patient_data = pd.DataFrame([patient_data])\n",
    "\n",
    "    # Drop target columns if they exist\n",
    "    cols_to_drop = [\"PatientID\", \"Side_Effect_Type\", \"Side_Effect_Severity\",\n",
    "                    \"Side_Effect_Timing\", \"Staff_Intervention_Required\",\n",
    "                    \"Side_Effect_Severity_Encoded\", \"Side_Effect_Timing_Encoded\",\n",
    "                    \"Staff_Intervention_Encoded\"]\n",
    "\n",
    "    for col in cols_to_drop:\n",
    "        if col in patient_data.columns:\n",
    "            patient_data = patient_data.drop(col, axis=1)\n",
    "\n",
    "    # Process the patient data\n",
    "    patient_processed = preprocessor.transform(patient_data)\n",
    "\n",
    "    # Get predictions from each specialized model\n",
    "    side_effect_pred = side_effect_model.predict(patient_processed)\n",
    "    severity_pred = severity_model.predict(patient_processed)\n",
    "    timing_pred = timing_model.predict(patient_processed)\n",
    "    intervention_pred = intervention_model.predict(patient_processed)\n",
    "\n",
    "    # Get prediction probabilities for more detailed analysis\n",
    "    side_effect_probs = []\n",
    "    for estimator in side_effect_model.estimators_:\n",
    "        side_effect_probs.append(estimator.predict_proba(patient_processed)[0])\n",
    "\n",
    "    severity_probs = severity_model.predict_proba(patient_processed)[0]\n",
    "    timing_probs = timing_model.predict_proba(patient_processed)[0]\n",
    "    intervention_probs = intervention_model.predict_proba(patient_processed)[0]\n",
    "\n",
    "    # Convert predictions to original categories\n",
    "    predicted_effects = []\n",
    "    for i, effect in enumerate(side_effect_mlb.classes_):\n",
    "        if side_effect_pred[0][i] == 1:\n",
    "            predicted_effects.append(effect)\n",
    "\n",
    "    if not predicted_effects:\n",
    "        predicted_effects = [\"None\"]\n",
    "\n",
    "    predicted_side_effects = \";\".join(predicted_effects)\n",
    "    predicted_severity = severity_encoder.inverse_transform(severity_pred)[0]\n",
    "    predicted_timing = timing_encoder.inverse_transform(timing_pred)[0]\n",
    "    predicted_intervention = intervention_encoder.inverse_transform(intervention_pred)[0]\n",
    "\n",
    "    # Create a confidence score for each prediction\n",
    "    side_effect_confidence = {}\n",
    "    for i, effect in enumerate(side_effect_mlb.classes_):\n",
    "        if side_effect_pred[0][i] == 1:\n",
    "            # Get the probability of class 1\n",
    "            confidence = side_effect_probs[i][1]\n",
    "            side_effect_confidence[effect] = float(confidence)\n",
    "\n",
    "    # Get the probability of the predicted class for each other model\n",
    "    severity_idx = severity_pred[0]\n",
    "    severity_confidence = float(severity_probs[severity_idx])\n",
    "\n",
    "    timing_idx = timing_pred[0]\n",
    "    timing_confidence = float(timing_probs[timing_idx])\n",
    "\n",
    "    intervention_idx = intervention_pred[0]\n",
    "    intervention_confidence = float(intervention_probs[intervention_idx])\n",
    "\n",
    "    # Return the predictions with confidence scores\n",
    "    return {\n",
    "        \"side_effects\": predicted_side_effects,\n",
    "        \"severity\": predicted_severity,\n",
    "        \"timing\": predicted_timing,\n",
    "        \"intervention_required\": predicted_intervention,\n",
    "        \"confidence\": {\n",
    "            \"side_effects\": side_effect_confidence,\n",
    "            \"severity\": severity_confidence,\n",
    "            \"timing\": timing_confidence,\n",
    "            \"intervention\": intervention_confidence\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"\\nThe models have been updated with specialized algorithms!\")\n",
    "print(\"- Side Effect Type: RandomForest (good for multi-label classification)\")\n",
    "print(\"- Severity: GradientBoosting (handles ordinal data well)\")\n",
    "print(\"- Timing: LightGBM (efficient for multi-class problems)\")\n",
    "print(\"- Intervention Required: LogisticRegression (interpretable for binary tasks)\")\n",
    "print(\"\\nYou can now use predict_side_effects() to get predictions with confidence scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
